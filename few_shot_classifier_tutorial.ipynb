{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from easyfsl.utils import sliding_average\n",
    "\n",
    "from get_processed_data import get_processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (12335, 55) (12335,)\n",
      "Validation set shape: (1542, 55) (1542,)\n",
      "Test set shape: (1542, 55) (1542,)\n"
     ]
    }
   ],
   "source": [
    "df, X_train, y_train, X_val, y_val, X_test, y_test = get_processed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototypical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork (nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(PrototypicalNetwork, self).__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    ## Predict query labels using labelled support data\n",
    "    def forward (self, support_data: torch.Tensor, support_labels: torch.Tensor, \n",
    "                 query_data: torch.Tensor) -> torch.Tensor:\n",
    "        ## Extract features / embedding of support and query data (using backbone)\n",
    "        z_support = self.backbone.forward(support_data)\n",
    "        z_query = self.backbone.forward(query_data)\n",
    "\n",
    "        ## Infer no. of unique classes from support set labels\n",
    "        n_way = len(torch.unique(support_labels))\n",
    "\n",
    "        ## Construct prototypes\n",
    "            ## Prototype i = Mean of embeddings of all support data with label i\n",
    "        z_proto = torch.cat(\n",
    "            [\n",
    "                z_support[torch.nonzero(support_labels == label)].mean(0) \\\n",
    "                    for label in range(n_way)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ## Compute euclidean distance from query data to prototypes, and classification scores\n",
    "        dists = torch.cdist(z_query, z_proto)\n",
    "        classification_scores = -dists ## Smaller distance -> Higher score\n",
    "\n",
    "        return classification_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training (meta-learning / episodic training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Episodic training simulates the few-shot learning scenario to train a prototypical network. Training data is organized into episodes that resemble few-shot tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 2\n",
    "N_SHOT = 5\n",
    "N_QUERY = 10\n",
    "\n",
    "N_TRAINING_EPISODES = 0 ## No. of tasks to sample (??)\n",
    "N_VALIDATION_TASKS = 0 ## (??)\n",
    "\n",
    "train_set = None ## (??)\n",
    "\n",
    "train_set.get_labels = None ## (??)\n",
    "## Requires dataset to be a FewShotDataset (??)\n",
    "train_sampler = TaskSampler(dataset = train_set, n_way = N_WAY, n_shot = N_SHOT, \n",
    "                            n_query = N_QUERY, n_tasks = N_TRAINING_EPISODES)\n",
    "## Loader generates an iterable given a dataset and a sampler\n",
    "train_loader = DataLoader(dataset = train_set, batch_sampler = train_sampler, pin_memory = True,\n",
    "                          collate_fn = train_sampler.episodic_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing optimizer, loss function and meta-training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss fn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "## Optimizer\n",
    "model = None ##TODO: Implement model\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "\n",
    "## Training loop\n",
    "    ## Takes a classification task as input (support & query set), makes prediction, \n",
    "    ## calculates loss, updates model params, returns loss\n",
    "def fit (optimizer, criterion, \n",
    "         support_data: torch.Tensor, support_labels: torch.Tensor, \n",
    "         query_data: torch.Tensor, query_labels: torch.Tensor) -> float:\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    classification_scores = model.forward(support_data, support_labels, query_data) ##TODO: Define method\n",
    "\n",
    "    loss = criterion(classification_scores, query_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_update_frequency = 10\n",
    "\n",
    "all_loss = []\n",
    "model.train()\n",
    "with tqdm(enumerate(train_loader), total = len(train_loader)) as tqdm_train:\n",
    "    for episode_index, (support_data, support_labels, query_data, query_labels, _) in tqdm_train:\n",
    "        episode_loss = fit(support_data, support_labels, query_data, query_labels)\n",
    "        all_loss.append(episode_loss)\n",
    "\n",
    "        if episode_index % log_update_frequency == 0:\n",
    "            tqdm_train.set_postfix(loss = sliding_average(all_loss, log_update_frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader) ##TODO: Implement method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt4012",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
